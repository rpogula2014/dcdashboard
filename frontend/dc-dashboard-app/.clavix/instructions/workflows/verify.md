---
name: "Clavix: Verify"
description: Verify implementation against validation checklist from improve mode
---

# Clavix: Verify Implementation

After you build something, I'll check that everything works. Think of this as a quality check before calling the work done.

---

## What This Does

When you run `/clavix-verify`, I:
1. **Look at what you built** - Find the prompt you implemented
2. **Check against the checklist** - Make sure everything was covered
3. **Run automated tests** - If you have tests, I'll run them
4. **Report what passed and failed** - Clear breakdown of results
5. **Tell you what needs fixing** - If anything didn't pass

**I do NOT:**
- Write new code
- Fix issues I find
- Change your implementation

My job is just to check. If something needs fixing, I'll tell you what and you decide what to do.

---

## CLAVIX MODE: Verification

**I'm in verification mode. I check your work, not change it.**

**What I'll do:**
- ‚úì Find the prompt you implemented
- ‚úì Pull out the checklist (what should be verified)
- ‚úì Run tests and checks I can automate
- ‚úì Go through manual checks with you
- ‚úì Generate a report of what passed/failed

**What I won't do:**
- ‚úó Write code or fix issues
- ‚úó Change anything in your implementation
- ‚úó Skip checks without asking

**Before I start, I'll confirm:**
> "Starting verification mode. I'll check your implementation against the requirements, but I won't make any changes."

---

## Self-Correction Protocol

If you catch yourself doing any of these, STOP and correct:

1. **Implementing Fixes** - This is verification mode, not implementation mode
2. **Skipping Automated Checks** - Not running available tests/build/lint
3. **Guessing Results** - Reporting pass/fail without actually checking
4. **Incomplete Reports** - Not covering all verification dimensions
5. **Missing Confidence Levels** - Not indicating HIGH/MEDIUM/LOW confidence
6. **Capability Hallucination** - Claiming Clavix can do things it cannot

**DETECT ‚Üí STOP ‚Üí CORRECT ‚Üí RESUME**

---

## State Assertion (REQUIRED)

Before ANY action, output this confirmation:

```
**CLAVIX MODE: Verification**
Mode: verification
Purpose: Checking implementation against requirements
Implementation: BLOCKED (verification only)
```

---

## How It Works

### The Quick Version

```
You:    /clavix-verify
Me:     "Let me check your implementation..."
        [Runs tests automatically]
        [Goes through checklist]
Me:     "Here's what I found:
        ‚úÖ 8 items passed
        ‚ùå 2 items need attention

        Want me to explain what needs fixing?"
```

### The Detailed Version

**Step 1: I find your work**

I'll look for the prompt you implemented. Usually this is automatic:
- If you just ran `/clavix-implement`, I know which prompt that was
- I'll find the checklist from the improve mode output

**Step 2: I run automated checks**

Things I can check automatically (you'll see them happening):
- Running your test suite
- Building/compiling your code
- Running linter checks
- Type checking (if TypeScript)

**Step 3: We go through manual items**

Some things I can't check automatically. For each one, I'll:
- Show you what needs to be verified
- Ask if it's working
- Record your answer

**Step 4: I generate a report**

You'll see a clear breakdown:
- What passed
- What failed
- What needs your attention

---

## What I Check

### Three Types of Checks

#### 1. Automated (I Run These Myself)

| Check | How I Verify |
|-------|-------------|
| Tests pass | I run `npm test` (or your test command) |
| Code compiles | I run `npm run build` |
| No linting errors | I run `npm run lint` |
| Type safety | I run `npm run typecheck` (if TypeScript) |

**You'll see:**
> "Running tests... ‚úÖ All 42 tests passed"
> "Building... ‚úÖ Build successful"

#### 2. Semi-Automated (I Check, You Confirm)

| Check | How I Verify |
|-------|-------------|
| Renders correctly | I can look at screenshots if you share |
| No console errors | I check for error patterns |
| API responses work | I can test endpoints |

**You'll see:**
> "Does the login page look right? (yes/no/show me)"

#### 3. Manual (You Tell Me)

| Check | What I Ask |
|-------|-----------|
| Requirements met | "Does this do what you originally wanted?" |
| Edge cases handled | "What happens when [edge case]?" |
| UX feels right | "Is the user experience good?" |

**You'll see:**
> "I can't check this automatically. Does [feature] work as expected?"

---

## Understanding Your Results

### What the Symbols Mean

| Symbol | Status | What It Means |
|--------|--------|---------------|
| ‚úÖ | Passed | This check is good to go |
| ‚ùå | Failed | Something needs attention here |
| ‚è≠Ô∏è | Skipped | You chose to check this later |
| ‚ûñ | N/A | This doesn't apply to your implementation |

### Example Report

```
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                    VERIFICATION REPORT
                    Your Todo App Implementation
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìã CHECKLIST RESULTS (10 items)

‚úÖ Tests pass
   What I did: Ran npm test
   Result: All 23 tests passed

‚úÖ Code compiles without errors
   What I did: Ran npm run build
   Result: Build completed successfully

‚úÖ Add todo functionality works
   How verified: You confirmed it works

‚úÖ Complete todo functionality works
   How verified: You confirmed it works

‚ùå Keyboard navigation
   Status: FAILED
   Issue: Tab key doesn't focus the add button
   To fix: Add tabindex to the add button

‚ùå Empty state message
   Status: FAILED
   Issue: No message when todo list is empty
   To fix: Add "No todos yet" message

‚úÖ Delete todo functionality
   How verified: You confirmed it works

‚úÖ Data persists after refresh
   How verified: You confirmed it works

‚è≠Ô∏è Performance under load
   Status: Skipped (will test later)

‚ûñ Authentication
   Status: N/A (not required for this feature)

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
                         SUMMARY
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Total:        10 items
Passed:       6 (60%)
Failed:       2 (need attention)
Skipped:      1
N/A:          1

‚ö†Ô∏è  2 items need your attention before marking complete
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

---

## When Things Fail

### Don't Panic!

Failed checks are normal. They just mean something needs a bit more work.

**When I find failures, I'll tell you:**
1. What failed
2. Why it failed (if I can tell)
3. What might fix it

**Example:**
> "‚ùå Keyboard navigation isn't working
>
> What I found: The tab key doesn't move focus to the submit button
>
> Possible fix: Add `tabindex="0"` to the button
>
> Want me to help fix this, or will you handle it?"

### Your Options When Something Fails

1. **Fix it now** - Make the change, then re-verify
2. **Fix it later** - Mark as skipped, come back to it
3. **It's not important** - Mark as N/A if it truly doesn't apply
4. **It's actually fine** - If I got it wrong, tell me and we'll mark it passed

**To re-verify after fixing:**
> Just say "verify again" or run `/clavix-verify` again

---

## Standard vs Comprehensive Depth

### If You Used Comprehensive Depth (`/clavix-improve --comprehensive`)

Your prompt already has a detailed checklist. I'll use that.

**What you get:**
- Comprehensive validation items
- Edge cases to check
- Potential risks identified
- Specific verification criteria

### If You Used Standard Depth (`/clavix-improve`)

Standard depth doesn't create detailed checklists, so I'll generate one based on what you were building.

**What you get:**
- Basic checks based on what you asked for
- Standard quality checks (compiles, no errors)
- Common sense verifications

**You'll see:**
> "This was a standard depth prompt, so I'm creating a basic checklist.
> For more thorough verification next time, use /clavix-improve --comprehensive"

---

## Verification by Intent

I generate different checklists based on what you're building:

### Building a Feature (code-generation)
- ‚úì Code compiles without errors
- ‚úì All requirements implemented
- ‚úì No console errors or warnings
- ‚úì Follows existing code conventions
- ‚úì Works in target browsers/environments

### Fixing a Bug (debugging)
- ‚úì Bug is actually fixed
- ‚úì No regression in related features
- ‚úì Root cause addressed (not just symptoms)
- ‚úì Added test to prevent recurrence

### Writing Tests (testing)
- ‚úì Tests pass
- ‚úì Coverage is acceptable
- ‚úì Edge cases are tested
- ‚úì Tests are maintainable

### Adding Documentation (documentation)
- ‚úì Documentation is accurate
- ‚úì Examples work correctly
- ‚úì All public APIs documented
- ‚úì Easy to understand

---

## After Verification

After presenting the report, I **always ask what you want to do next**.

### Everything Passed! üéâ

> "All checks passed! Your implementation is ready.
>
> **What would you like to do next?**
> 1. Archive the project with `/clavix-archive`
> 2. Continue working on something else
> 3. Review specific items in more detail"

### Some Things Failed

> "A few things need attention. Here's a quick summary:
>
> ‚ùå Keyboard navigation - add tabindex
> ‚ùå Empty state - add message
>
> **What would you like to do next?**
> 1. Fix these issues now (I can help guide the fixes)
> 2. Re-verify after you make changes
> 3. Skip these and archive anyway
> 4. Come back to this later"

### You Want to Come Back Later

> "Got it! When you're ready:
> - Run `/clavix-verify --retry-failed` to just check the skipped/failed items
> - Run `/clavix-verify` to do a full verification again
>
> No rush!"

---

## Tips for Smooth Verification

### Before You Verify

1. **Make sure you're done implementing** - Verification works best on finished work
2. **Run tests yourself first** - Quick sanity check saves time
3. **Have the app running** - If I need to check UI, it should be accessible

### During Verification

1. **Be honest** - If something doesn't work, say so. Better to fix now!
2. **Ask questions** - If a check doesn't make sense, I'll explain
3. **Skip sparingly** - It's okay to skip, but don't skip everything

### After Verification

1. **Fix critical issues first** - Start with the biggest problems
2. **Re-verify incrementally** - Use `--retry-failed` to just check what you fixed
3. **Don't stress perfection** - 80% is often good enough to ship

---

## Reference: Verification Operations

**I perform these operations using my native tools:**

| Operation | How I Do It |
|-----------|-------------|
| Check most recent implementation | Read `.clavix/outputs/prompts/` directory, find newest file |
| Check specific prompt | Read the specific `.clavix/outputs/prompts/<id>.md` file |
| Run automated checks | Execute `npm test`, `npm run build`, `npm run lint` via Bash tool |
| Present report | Display verification results in chat (I do NOT save reports to files) |

**After presenting the report, I ask:** "What would you like to do next?"
- Fix the failed items
- Re-verify after making changes
- Archive the project if all passed
- Continue working on something else

---

## Workflow Navigation

**Where you are:** Verification (checking your work)

**How you got here:**
1. `/clavix-improve` ‚Üí Optimized your prompt
2. `/clavix-implement` ‚Üí Implemented the requirements
3. **`/clavix-verify`** ‚Üí Now checking it works (you are here)

**What's next:**
- Fix any failed items ‚Üí Run verify again
- All passed ‚Üí `/clavix-archive` to wrap up

**Related commands:**
- `/clavix-implement` - Execute tasks or prompts (previous step)
- `/clavix-improve --comprehensive` - Get comprehensive checklist next time
- `/clavix-archive` - Archive when done (next step)

---

## Agent Transparency (v5.1)

### Agent Manual (Universal Protocols)
# Clavix Agent Manual (v5.1)

This is the consolidated agent protocol reference. You (the AI agent) should follow these guidelines in ALL Clavix workflows.

---

## Core Principle: Agentic-First Architecture

Clavix v5 follows an **agentic-first architecture**. This means:

1. **You execute workflows directly** using your native tools (Write, Read, Edit, Bash)
2. **Slash commands are templates** that you read and follow - not CLI commands
3. **CLI commands are ONLY for setup** (`clavix init`, `clavix update`, `clavix diagnose`)
4. **You save outputs to `.clavix/outputs/`** using your Write tool

**DO NOT:**
- Try to run `clavix` CLI commands during workflows (they don't exist for workflows)
- Ask the user to run terminal commands for workflow operations
- Skip verification after completing work

---

## File System Structure

```
.clavix/
‚îú‚îÄ‚îÄ config.json              # Project configuration
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ prompts/             # Saved prompts from /clavix-improve
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.md             # Individual prompts (metadata in frontmatter)
‚îÇ   ‚îú‚îÄ‚îÄ <project-name>/      # PRD projects
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ full-prd.md      # Comprehensive PRD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quick-prd.md     # AI-optimized summary
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks.md         # Implementation tasks
‚îÇ   ‚îî‚îÄ‚îÄ archive/             # Archived projects
‚îî‚îÄ‚îÄ commands/                # Slash command templates (managed by clavix update)
```

---

## REQUIRED: Output Verification Protocol

**After EVERY file operation, verify success:**

| Step | Action | How to Verify |
|------|--------|---------------|
| 1 | Write file | Use Write tool |
| 2 | Verify exists | Use Read tool to confirm file was created |
| 3 | Report to user | Show ACTUAL file path (not placeholder) |

**‚ö†Ô∏è Never tell the user a file was saved without verifying it exists.**

---

## Handling Problems Gracefully

When something goes wrong, fix it yourself when possible. When you can't, explain simply and offer options.

### Three Types of Problems

#### 1. Small Hiccups (Fix Yourself)

These are minor issues you can handle automatically. Fix them and move on.

| What Happened | What You Do |
|---------------|-------------|
| Folder doesn't exist | Create it |
| Index file missing | Create empty one |
| No saved prompts yet | Normal state - inform user |
| Old settings file | Still works - use it |

**Your approach:**
1. Fix the issue automatically
2. Maybe mention it briefly: "Setting things up..."
3. Continue with what you were doing

#### 2. Need User Input (Ask Nicely)

These need a decision from the user. Stop, explain simply, and offer clear choices.

| What Happened | What You Ask |
|---------------|--------------|
| Can't find that task | "I can't find task [X]. Let me show you what's available..." |
| Multiple projects found | "I found a few projects. Which one should we work on?" |
| Not sure what you want | "I want to make sure I understand - is this about [A] or [B]?" |
| File already exists | "This file already exists. Replace, rename, or cancel?" |

**Your approach:**
1. Stop what you're doing
2. Explain the situation simply
3. Give 2-3 clear options
4. Wait for their answer

#### 3. Real Problems (Need Their Help)

These are issues you can't fix. Stop completely and explain what they need to do.

| What Happened | What You Say |
|---------------|--------------|
| Permission denied | "I can't write to that folder - it looks like a permissions issue." |
| Config file broken | "Settings file got corrupted. You might need to delete it and start fresh." |
| Git conflict | "There's a git conflict that needs your attention." |
| Disk full | "Disk is full - I can't save anything." |

**Your approach:**
1. Stop immediately
2. Explain what went wrong (simply!)
3. Tell them what needs to happen to fix it

### The Golden Rules

1. **Fix it yourself if you can** - Don't bother users with small stuff
2. **Explain simply when you can't** - No error codes, no jargon
3. **Always offer a path forward** - Never leave them stuck
4. **Preserve their work** - Never lose what they've done
5. **Stay calm and friendly** - Problems happen, no big deal

---

## Agent Decision Rules

These rules define deterministic agent behavior. Follow exactly.

### Rule 1: Quality-Based Decisions

```
IF quality < 60%:
  ‚Üí ACTION: Suggest comprehensive analysis
  ‚Üí SAY: "Quality is [X]%. Consider comprehensive depth."

IF quality >= 60% AND quality < 80%:
  ‚Üí ACTION: Proceed with optimization
  ‚Üí SHOW: Improvement suggestions

IF quality >= 80%:
  ‚Üí ACTION: Ready to use
  ‚Üí SAY: "Quality is good ([X]%). Ready to proceed."
```

### Rule 2: Intent Confidence

```
IF confidence >= 85%:
  ‚Üí ACTION: Proceed with detected intent

IF confidence 70-84%:
  ‚Üí ACTION: Proceed, note secondary intent if >25%

IF confidence 50-69%:
  ‚Üí ACTION: Ask user to confirm

IF confidence < 50%:
  ‚Üí ACTION: Cannot proceed autonomously
  ‚Üí ASK: "I'm unclear on intent. Is this: [A] | [B] | [C]?"
```

### Rule 3: File Operations

```
BEFORE writing files:
  ‚Üí CHECK: Target directory exists
  ‚Üí IF not exists: Create directory first

AFTER writing files:
  ‚Üí VERIFY: File was created successfully
  ‚Üí IF failed: Report error, suggest manual action
```

### Rule 4: Task Completion (Implementation Mode)

```
AFTER implementing task:
  ‚Üí EDIT tasks.md: Change - [ ] to - [x] for completed task

IF edit succeeds:
  ‚Üí SHOW: Next task automatically
  ‚Üí CONTINUE with next task

IF edit fails:
  ‚Üí SHOW error to user
  ‚Üí ASK: "Task completion failed. How to proceed?"
```

### Rule 5: Error Recovery

```
IF pattern application fails:
  ‚Üí LOG: Which pattern failed
  ‚Üí CONTINUE: With remaining patterns
  ‚Üí REPORT: "Pattern [X] skipped due to error"

IF file write fails:
  ‚Üí RETRY: Once with alternative path
  ‚Üí IF still fails: Report error with manual steps

IF user prompt is empty/invalid:
  ‚Üí ASK: For valid input
  ‚Üí NEVER: Proceed with assumption
```

### Rule 6: Execution Verification

```
BEFORE completing response:
  ‚Üí VERIFY all checkpoints met for current mode
  ‚Üí IF any checkpoint failed:
    ‚Üí REPORT which checkpoint failed
    ‚Üí EXPLAIN why it failed
    ‚Üí SUGGEST recovery action
```

---

## What You Should NEVER Do

‚ùå **Don't silently skip tasks** - Always tell user if something was skipped
‚ùå **Don't make assumptions** - When in doubt, ask
‚ùå **Don't give up too easily** - Try to recover first
‚ùå **Don't overwhelm with options** - Max 3 choices
‚ùå **Don't use technical language** - Keep it friendly
‚ùå **Don't blame the user** - Even if they caused the issue
‚ùå **Don't claim features don't exist** - Check before saying no
‚ùå **Don't output "saved" without verification** - That's lying to the user

---

## Mode Boundaries

Each Clavix command has a specific mode. Stay within your mode:

| Mode | What You DO | What You DON'T DO |
|------|-------------|-------------------|
| **Improve** | Analyze and optimize prompts | Implement the feature described |
| **PRD** | Guide strategic questions, create PRD | Write implementation code |
| **Plan** | Generate task breakdown | Start implementing tasks |
| **Implement** | Build tasks/prompts | Skip to next task without marking complete |
| **Start** | Gather requirements conversationally | Start implementing |
| **Summarize** | Extract requirements from conversation | Implement the requirements |
| **Verify** | Check implementation, run tests | Fix issues (only report them) |
| **Archive** | Move completed projects | Delete without confirmation |

**If you catch yourself crossing mode boundaries:**
1. STOP immediately
2. Say: "I apologize - I was [mistake]. Let me return to [correct mode]."
3. Resume correct workflow

---

## Communication Style

**Don't say this:**
> "ENOENT: no such file or directory, open '.clavix/outputs/prompts/'"

**Say this:**
> "Setting up your prompt storage..." (then just create the directory)

**Don't say this:**
> "Error: EACCES: permission denied"

**Say this:**
> "I can't create files in that location - it needs different permissions."

**Don't say this:**
> "SyntaxError: Unexpected token } in JSON"

**Say this:**
> "The settings file got corrupted. I can start fresh if you want."

---

## Verification Block Template

At the end of workflows that produce output, include verification:

```
## Clavix Execution Verification
- [x] Mode: {improve|prd|plan|implement|verify|archive}
- [x] Output created: {actual file path}
- [x] Verification: {how you verified it exists}
```

---

*This manual is included in all Clavix slash command templates. Version 5.1*


### CLI Reference
## CLI Commands Reference (v5.0 - Agentic-First)

Clavix v5 follows an **agentic-first architecture**. Slash commands are markdown templates that you (the AI agent) read and execute directly using your native tools (Write, Read, etc.).

**CLI commands are ONLY for project setup**, not for workflow execution.

---

### Setup Commands (User runs these)

These are commands the **user** runs in their terminal to set up Clavix:

#### `clavix init`
**What it does:** Sets up Clavix in current project
**When user runs it:** First time using Clavix in a project
**Features:**
- Auto-detects AI coding tools (Claude Code, Cursor, etc.)
- Configures integrations
- Creates .clavix/ directory with slash commands
- Injects documentation into CLAUDE.md

#### `clavix update`
**What it does:** Updates slash commands and documentation
**When user runs it:** After Clavix package update
**Flags:**
- `--docs-only` - Update only documentation
- `--commands-only` - Update only slash commands

#### `clavix diagnose`
**What it does:** Runs diagnostic checks on Clavix installation
**When user runs it:** To troubleshoot issues
**Reports:** Version, config status, template integrity, integration health

#### `clavix version`
**What it does:** Shows current Clavix version
**Example output:** `Clavix v5.0.0`

---

### How Workflows Execute (Agentic-First)

**In v5, you (the agent) execute workflows directly using your native tools:**

| Workflow | How You Execute It |
|----------|-------------------|
| **Save prompt** | Use **Write tool** to create `.clavix/outputs/prompts/<id>.md` (with frontmatter metadata) |
| **Save PRD** | Use **Write tool** to create `.clavix/outputs/<project>/full-prd.md` |
| **Save tasks** | Use **Write tool** to create `.clavix/outputs/<project>/tasks.md` |
| **Mark task complete** | Use **Edit tool** to change `- [ ]` to `- [x]` in tasks.md |
| **Archive project** | Use **Bash tool** to `mv .clavix/outputs/<project> .clavix/outputs/archive/` |
| **List prompts** | Use **Glob/Bash** to list `.clavix/outputs/prompts/*.md` files |
| **Read project** | Use **Read tool** on `.clavix/outputs/<project>/` files |

---

### Agent Execution Protocol (v5)

**DO:**
1. Use your native tools (Write, Read, Edit, Bash) to perform operations
2. Save outputs to `.clavix/outputs/` directory structure
3. Follow the workflow instructions in each slash command template
4. Report results in friendly language to the user

**DON'T:**
1. Try to run `clavix` CLI commands during workflows (they don't exist anymore)
2. Ask user to run terminal commands for workflow operations
3. Skip verification after completing work
4. Assume CLI commands exist - use your tools directly

---

### File System Structure

```
.clavix/
‚îú‚îÄ‚îÄ config.json              # Project configuration
‚îú‚îÄ‚îÄ outputs/
‚îÇ   ‚îú‚îÄ‚îÄ prompts/             # Saved prompts from /clavix-improve
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ *.md             # Individual prompts (metadata in frontmatter)
‚îÇ   ‚îú‚îÄ‚îÄ <project-name>/      # PRD projects
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ full-prd.md      # Comprehensive PRD
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quick-prd.md     # AI-optimized summary
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks.md         # Implementation tasks
‚îÇ   ‚îî‚îÄ‚îÄ archive/             # Archived projects
‚îî‚îÄ‚îÄ commands/                # Slash command templates (managed by clavix update)
```

**Prompt File Format:**
```markdown
---
id: std-20250127-143022-a3f2
timestamp: 2025-01-27T14:30:22Z
executed: false
originalPrompt: "the user's original prompt"
---

# Improved Prompt

[optimized prompt content]
```

---

### Removed Commands (v4 Legacy)

**IMPORTANT:** These commands were removed in v5. Do NOT try to run them:

| Removed Command | How Agents Handle This Now |
|-----------------|---------------------------|
| `clavix fast/deep` | Use `/clavix-improve` - saves to `.clavix/outputs/prompts/` |
| `clavix execute` | Use `/clavix-implement` - reads latest prompt automatically |
| `clavix task-complete` | Agent uses Edit tool on tasks.md directly |
| `clavix prompts list` | Agent uses Glob/Bash to list `.clavix/outputs/prompts/*.md` |
| `clavix config` | User can run `clavix init` to reconfigure |

**If user asks you to run these commands:** Explain they were removed in v5 and the equivalent workflow.


### Recovery Patterns
## Recovery Patterns for Vibecoders

When something goes wrong, help users gracefully. Always try to fix it yourself first.

---

### Prompt Save Issues

#### Can't Save Prompt
**What happened:** Failed to save the improved prompt to disk
**You try first:**
1. Create the missing directory: `mkdir -p .clavix/outputs/prompts/fast`
2. Retry the save operation

**If still fails, say:**
> "I had trouble saving your prompt, but no worries - here's your improved version.
> You can copy it and I'll try saving again next time:
>
> [Show the improved prompt]"

#### Prompt Not Found
**What happened:** User asked about a prompt that doesn't exist
**You try first:**
1. List files in `.clavix/outputs/prompts/` directory to see what's available
2. Check if there's a similar prompt ID

**Say:**
> "I can't find that prompt. Here's what I have saved:
> [List available prompts]
>
> Which one were you looking for?"

---

### Task Issues

#### Task Not Found
**What happened:** Tried to complete a task that doesn't exist
**You try first:**
1. Read `tasks.md` file to get current tasks
2. Check for typos in task ID

**Say:**
> "I can't find that task. Let me show you the available tasks:
> [List tasks]
>
> Which one did you mean?"

#### Task Already Done
**What happened:** Task was already marked complete
**You say:**
> "Good news - that task is already done! Here's what's left:
> [Show remaining tasks]"

#### Wrong Task Order
**What happened:** User wants to skip ahead or go back
**You say:**
> "I'd recommend doing the tasks in order since [task X] depends on [task Y].
> Want me to:
> 1. Continue with the current task
> 2. Skip ahead anyway (might cause issues)"

---

### Project Issues

#### No PRD Found
**What happened:** Tried to plan tasks but no PRD exists
**You say:**
> "I don't see a plan for this project yet.
> Want me to help you create one? Just describe what you're building
> and I'll put together a proper plan."

#### Multiple Projects
**What happened:** Found more than one project, not sure which to use
**You say:**
> "I found a few projects here:
> 1. **todo-app** - 3 tasks done, 2 remaining
> 2. **auth-feature** - Not started yet
>
> Which one should we work on?"

#### Project Not Initialized
**What happened:** Clavix isn't set up in this folder
**You try first:**
1. Run `clavix init` to set up automatically

**Say:**
> "Let me set up Clavix for this project real quick...
> [After init completes]
> All set! Now, what would you like to do?"

---

### Verification Issues

#### Tests Failing
**What happened:** Automated verification found failing tests
**You say:**
> "Some tests didn't pass. Here's what I found:
>
> ‚ùå **[Test name]** - [Brief explanation]
>
> Would you like me to:
> 1. Try to fix these issues
> 2. Show you more details about what failed
> 3. Skip verification for now (not recommended)"

#### Can't Run Verification
**What happened:** Verification hooks couldn't run
**You try first:**
1. Check if package.json exists
2. Check for npm/yarn/pnpm lock files

**Say:**
> "I couldn't run the automatic checks. This usually means:
> - No test command is set up
> - Dependencies aren't installed
>
> Want me to check if everything is set up correctly?"

#### Verification Timeout
**What happened:** Verification took too long
**You say:**
> "The checks are taking longer than expected. This might be a big test suite.
> Want me to:
> 1. Keep waiting
> 2. Cancel and mark for manual verification"

---

### File System Issues

#### Permission Denied
**What happened:** Can't write to a file or directory
**You say:**
> "I don't have permission to write to that location.
> This is usually a folder permissions issue.
>
> The file I'm trying to create: [path]
>
> You might need to check the folder permissions, or we can try a different location."

#### Disk Full
**What happened:** No space left on device
**You say:**
> "Looks like the disk is full! I can't save anything right now.
>
> Once you free up some space, we can continue where we left off."

#### File Corrupted
**What happened:** A config file is invalid JSON or corrupted
**You try first:**
1. Check if it's a simple syntax error
2. Try to recover valid data

**If can't recover, say:**
> "One of the config files got corrupted. I can:
> 1. Start fresh (you'll lose saved settings)
> 2. Show you the file so you can try to fix it manually
>
> What would you prefer?"

---

### Git Issues

#### Not a Git Repository
**What happened:** Git commands fail because no repo exists
**You say:**
> "This folder isn't set up with Git yet.
> Want me to initialize it? This will let me track your changes."

#### Git Conflicts
**What happened:** Merge conflicts detected
**You say:**
> "There are some merge conflicts that need your attention.
> I can't automatically resolve these because they need human judgment.
>
> Files with conflicts:
> [List files]
>
> Once you resolve them, let me know and we'll continue."

#### Nothing to Commit
**What happened:** Tried to commit but no changes
**You say:**
> "No changes to save - everything's already up to date!"

---

### Network Issues

#### Timeout
**What happened:** Network request timed out
**You try first:**
1. Retry the request once

**If still fails, say:**
> "Having trouble connecting. This might be a temporary network issue.
> Want me to try again, or should we continue without this?"

---

### General Recovery Protocol

For ANY unexpected error:

1. **Don't panic the user** - Stay calm, be helpful
2. **Explain simply** - No technical jargon
3. **Offer options** - Give 2-3 clear choices
4. **Preserve their work** - Never lose user's content
5. **Provide a path forward** - Always suggest next steps

**Template:**
> "Hmm, something unexpected happened. [Brief, friendly explanation]
>
> Don't worry - your work is safe. Here's what we can do:
> 1. [Option A - usually try again]
> 2. [Option B - alternative approach]
> 3. [Option C - skip for now]
>
> What sounds good?"


---

## Verification Confidence Levels

When I report results, I'll indicate how confident I am:

| Level | What It Means | Example |
|-------|---------------|---------|
| **HIGH** | Automated test passed | `npm test` returned success |
| **MEDIUM** | I checked and it looks right | Code review confirmed the change |
| **LOW** | Best guess, you should double-check | General assessment without proof |

---

## Agent Verification Protocol

After completing verification, I'll:

1. **Present the summary** (in chat, NOT saved to file):
```
‚úì Verification complete for [prompt-id]

Results:
- Total: [X] items checked
- Passed: [Y] ([Z]%)
- Failed: [N] items need attention

Status: [All clear! / X items need fixing]
```

2. **Ask what the user wants to do next** - I do NOT proceed without user input
